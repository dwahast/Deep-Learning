{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwahast/Deep-learning/blob/master/MLP_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T_RsmTkQ98Vz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Objetivos deste trabalho\n",
        "- Familiarizar-se com a biblioteca PyTorch\n",
        "- Definir arquiteturas MLP simples em PyTorch\n",
        "- Treinar utilizando CIFAR10, testando diferentes arquiteturas, parâmetros, funções de loss e otimizadores\n",
        "- Comparar os resultados obtidos utilizando apenas Perpceptrons\n",
        "- Link útil (https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c)"
      ]
    },
    {
      "metadata": {
        "id": "qUwhuYBi98V2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn.functional as F # softmax\n",
        "\n",
        "#import pandas as pd # organize files \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LU2fLgnR98WA",
        "colab_type": "code",
        "outputId": "c9605e44-2b99-4293-a987-3302f5f237c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# Carregar os datasets\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 169713664/170498071 [00:27<00:00, 7613605.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A-o4YkPr98WI",
        "colab_type": "code",
        "outputId": "8ebd86ce-82bb-4171-c241-37a398a96b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=dataset_train, shuffle=True)\n",
        "test_loader = DataLoader(dataset=dataset_test, shuffle=False)\n",
        "print(len(test_loader))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L36yfjGr98WO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura MLP\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.activation_function = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = self.activation_function(self.fc1(x))\n",
        "        x = self.activation_function(self.fc2(x))\n",
        "        return x\n",
        "# Arquitecture with RELU      \n",
        "class MLP_relu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_relu, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.log_softmax(self.fc2(x),dim =1)\n",
        "        return x\n",
        "      \n",
        "# New Arquitecture with RELU   \n",
        "class MLP_Srelu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_Srelu, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 32)\n",
        "        self.fc4 = nn.Linear(32, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x),dim =1)\n",
        "        return x   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DSF3ZnQ98WT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_std = MLP()\n",
        "model_relu = MLP_relu()\n",
        "model_Srelu = MLP_Srelu()\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rh1fBZcW98WZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definir otimizador e loss\n",
        "# Nota: testar outros otimizadores e funções de loss (em particular cross entropy)\n",
        "\n",
        "def optimizer_set(model,optimizer_method, learning_rate):\n",
        "  if optimizer_method == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"adadelta\":\n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"adagrad\":\n",
        "    optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"adamax\":\n",
        "    optimizer = torch.optim.Adamax(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"rms\":\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "  return optimizer\n",
        "\n",
        "def loss_function_set(loss_function):\n",
        "  if loss_function == \"mse\":\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "  elif loss_function == \"nllos\":\n",
        "     loss_fn = torch.nn.NLLoss()\n",
        "  elif loss_function == \"cross\":\n",
        "     loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  return loss_fn\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZG-R1kCQEweC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(label, output_size):\n",
        "    \n",
        "    label_select = np.zeros(output_size)\n",
        "    label_select[label]=1\n",
        "    \n",
        "    return torch.Tensor(label_select)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p87aRLgR2pPo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, loss_function, dataset):\n",
        "  model.eval() # set model to Evaluate \"mode\"\n",
        " # losses = []\n",
        "  corrects = 0\n",
        "  current_total = 0\n",
        "  accuracies = 0\n",
        "  \n",
        " # loss_fn = loss_function_set(loss_function)\n",
        "  \n",
        "  for image, label in dataset:\n",
        "    outputs = model(image)\n",
        "    \n",
        "   # if(loss_function == 'mse'):\n",
        "   #   label_target = one_hot(label,10) # one_hot to set the training class in the escalar\n",
        "   #   loss = loss_fn(outputs,label_target)\n",
        "   # else:\n",
        "   #   loss = loss_fn(outputs,label)\n",
        "      \n",
        "   # losses.append(loss.item())\n",
        "    \n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "    if(predicted==label):\n",
        "      corrects += 1\n",
        "    \n",
        "    current_total += 1\n",
        "  \n",
        "  accuracy = corrects/current_total\n",
        "\n",
        "  return accuracy #, np.mean(losses)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFVQOHzayfj6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training function"
      ]
    },
    {
      "metadata": {
        "id": "MELtsUbB98Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Realizar o treinamento aqui\n",
        "def fit(model, epochs, optimizer_method, loss_function, learning_rate):\n",
        "  \n",
        "  print(\"Opt Method:\", optimizer_method.upper(), \"| Loss Function:\", loss_function.upper(), \"| Learning Rate:\", learning_rate)\n",
        "  optimizer = optimizer_set(model,optimizer_method, learning_rate) #optimizer and Learning rate setter\n",
        "  loss_fn = loss_function_set(loss_function) \n",
        "  accuracies = []\n",
        "  losses = []\n",
        "  train_acc = []\n",
        "  for epoch in range(epochs):\n",
        "    model.train() # Set model to TRAIN \"mode\" (can be set to False for Test)\n",
        "    epoch_losses = []\n",
        "    for image,label in train_loader:\n",
        "      optimizer.zero_grad()  # cleaning gradients between mini batches\n",
        "      outputs = model(image) \n",
        "     \n",
        "      if(loss_function == 'mse'):\n",
        "        label_target = one_hot(label,10) # one_hot to set the training class in the escalar\n",
        "        loss = loss_fn(outputs,label_target)\n",
        "      else: \n",
        "        loss = loss_fn(outputs, label)\n",
        "        \n",
        "      loss.backward() # Backpropagation \n",
        "      optimizer.step() # Optimization Method\n",
        "      \n",
        "      epoch_losses.append(loss.item())\n",
        "\n",
        "    losses.append(np.mean(epoch_losses)) # Append mean losses for each epoch\n",
        "   \n",
        "    \n",
        "    acc = evaluate(model, loss_function, train_loader)\n",
        "    train_acc.append(acc)\n",
        "    acc = evaluate(model, loss_function, test_loader) #evaluate\n",
        "    accuracies.append(acc)\n",
        "    \n",
        "    #if(epoch%10==0):\n",
        "    print(\"Epoch:\",epoch, \"- Average loss:\", np.mean(epoch_losses),\"- Accuracy:\", acc) # Print mean Loss for each epoch\n",
        " \n",
        "  return {\n",
        "      \"Model\": outputs,\n",
        "      \"Acc\": accuracies,\n",
        "      \"Train Acc\": train_acc,\n",
        "      \"Loss\": losses,\n",
        "      \"Name\": optimizer_method + \" | \" + loss_function + \" | \" + str(learning_rate),\n",
        "      \"Arc\": model\n",
        "      #\"Evaluate Train Loss\": train_losses,\n",
        "      \n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFeR8SBEw0ue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Your Model\n",
        "- Variable \"trained_models\" append all models trained\n",
        "- function \"fit\" train and return the Model and the all variable that will be used latter\n",
        "  - *fit(Model, Epochs, Optimizer method, Loss function, Learning rate, momentum)*"
      ]
    },
    {
      "metadata": {
        "id": "6kAvty-S98Wk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo aqui (no conjunto de teste)\n",
        "trained_models = []\n",
        "ep = 15 #epocas\n",
        "trained_models.append(fit(model_Srelu,ep,\"sgd\", \"cross\", 0.01))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7s50jzco4K-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trained_models.append(fit(model_relu,ep,\"sgd\",   \"cross\", 0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l9qX0-UwOR9K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trained_models.append(fit(model_std,ep,\"sgd\", \"cross\", 0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEYr1-Z1wlq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text and Graphical Output"
      ]
    },
    {
      "metadata": {
        "id": "qD3jggrzfXa9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.title(\"\\nAccuracy\", fontsize=20, loc=\"left\")\n",
        "for models in trained_models:\n",
        "  plt.plot(models[\"Acc\"], label=models[\"Name\"])\n",
        "  plt.plot(models[\"Train Acc\"],\"--\") \n",
        "  print(models[\"Arc\"],\"\\n\",models[\"Name\"], \"| ACC: \", np.mean(models[\"Acc\"]),\"\\n\")\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}