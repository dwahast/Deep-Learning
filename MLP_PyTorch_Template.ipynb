{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP PyTorch - Template.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwahast/Deep-learning/blob/master/MLP_PyTorch_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T_RsmTkQ98Vz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Objetivos deste trabalho\n",
        "- Familiarizar-se com a biblioteca PyTorch\n",
        "- Definir arquiteturas MLP simples em PyTorch\n",
        "- Treinar utilizando CIFAR10, testando diferentes arquiteturas, parâmetros, funções de loss e otimizadores\n",
        "- Comparar os resultados obtidos utilizando apenas Perpceptrons"
      ]
    },
    {
      "metadata": {
        "id": "qUwhuYBi98V2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LU2fLgnR98WA",
        "colab_type": "code",
        "outputId": "d7a6b537-e1cf-4e00-cff5-5ec47a46690d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Carregar os datasets\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A-o4YkPr98WI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=dataset_train, shuffle=True)\n",
        "test_loader = DataLoader(dataset=dataset_test, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L36yfjGr98WO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura MLP\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.activation_function = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = self.activation_function(self.fc1(x))\n",
        "        x = self.activation_function(self.fc2(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DSF3ZnQ98WT",
        "colab_type": "code",
        "outputId": "f1d755a2-eefe-465b-f03d-9c23a307b373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "model = MLP()\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=1024, out_features=20, bias=True)\n",
            "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (activation_function): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rh1fBZcW98WZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definir otimizador e loss\n",
        "# Nota: testar outros otimizadores e funções de loss (em particular cross entropy)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "#loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZG-R1kCQEweC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(label, output_size):\n",
        "    \n",
        "    label_select = np.zeros(output_size)\n",
        "    label_select[label]=1\n",
        "    \n",
        "    return torch.Tensor(label_select)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MELtsUbB98Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Realizar o treinamento aqui\n",
        "def fit(epochs):\n",
        "  losses = []\n",
        "  for epoch in range(epochs):\n",
        "    model.train() # Set model to TRAIN \"mode\" (can be set to False for Test)\n",
        "    batch_losses = []\n",
        "    for image,label in train_loader:\n",
        "      optimizer.zero_grad()  # cleaning gradients between mini batches\n",
        "      weights = model(image) \n",
        "      label_target = one_hot(label,10) # one_hot to set the training class in the escalar\n",
        "      loss = loss_fn(weights,label_target)\n",
        "      loss.backward() # Backpropagation \n",
        "      optimizer.step() # Optimization Method\n",
        "      batch_losses.append(loss.item())\n",
        "\n",
        "    losses.append(np.mean(batch_losses)) # Append mean losses for each epoch\n",
        "    #print(epoch, np.mean(batch_losses)) # Print Loss for each epoch\n",
        "\n",
        "  plt.plot(losses)\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kAvty-S98Wk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo aqui (no conjunto de teste)\n",
        "fit(100)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}