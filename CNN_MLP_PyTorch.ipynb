{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MLP_PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwahast/Deep-learning/blob/master/CNN_MLP_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T_RsmTkQ98Vz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Objetivos deste trabalho\n",
        "- Familiarizar-se com a biblioteca PyTorch\n",
        "- Definir arquiteturas MLP simples em PyTorch\n",
        "- Treinar utilizando CIFAR10, testando diferentes arquiteturas, parâmetros, funções de loss e otimizadores\n",
        "- Comparar os resultados obtidos utilizando apenas Perpceptrons\n",
        "- Link útil (https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c)"
      ]
    },
    {
      "metadata": {
        "id": "qUwhuYBi98V2",
        "colab_type": "code",
        "outputId": "2c64b63f-d676-44b9-d4ef-b204876109b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn.functional as F # softmax/relu\n",
        "\n",
        "print(torch.cuda.is_available())\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LU2fLgnR98WA",
        "colab_type": "code",
        "outputId": "576b7749-880c-4f2f-9c9d-90acb4f6836b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Carregar os datasets\n",
        "\n",
        "#transform=transforms.Compose([\n",
        "#    transforms.Grayscale(num_output_channels=1),\n",
        "#    transforms.ToTensor()\n",
        "#])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "#normaliza o dataset de test mas sem data augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/170498071 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 170008576/170498071 [00:10<00:00, 16447869.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A-o4YkPr98WI",
        "colab_type": "code",
        "outputId": "211494ac-bac9-4780-c17b-7af648516102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=dataset_train, shuffle=True, batch_size=32)\n",
        "test_loader = DataLoader(dataset=dataset_test, shuffle=False, batch_size=4)\n",
        "print(len(test_loader))\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.size())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500\n",
            "torch.Size([32, 3, 32, 32])\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NCdXG0yUlr3A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        \n",
        "        self.conv_layer = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,stride=1, padding=1),\n",
        "          nn.BatchNorm2d(32),   \n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          nn.Dropout2d(p=0.05),\n",
        "\n",
        "          nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(256),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          )  \n",
        "        \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            \n",
        "          #Flatten the feature maps. You have 32 feature mapsfrom cnn2. Each of the feature is of size 16x16 --> 32*16*16 = 8192\n",
        "          nn.Dropout(p=0.1),    #Dropout used to reduce overfitting \n",
        "          nn.Linear(32*32*4, 2048),   #Flattened image is fed into linear NN and reduced to half size\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(2048, 512),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(512, 128),\n",
        "          nn.Dropout(p=0.1),\n",
        "          nn.Linear(128, 10)    #Since there were so many features, I decided to use 45 layers to get output layers. You can increase the kernels in Maxpooling to reduce image further and reduce number of hidden linear layers.\n",
        "\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L36yfjGr98WO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura MLP\n",
        "# New Arquitecture with RELU   \n",
        "class MLP_Srelu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_Srelu, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 32)\n",
        "        self.fc4 = nn.Linear(32, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x),dim =1)\n",
        "        return x   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DSF3ZnQ98WT",
        "colab_type": "code",
        "outputId": "fda69774-1af9-4ea6-fee8-8ef124d5924d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_Srelu = MLP_Srelu()\n",
        "model_CNN = CNN()\n",
        "\n",
        "model_Srelu = model_Srelu.to(device)\n",
        "model_CNN = model_CNN.to(device)\n",
        "print(\"******** CUDA MODEL ENABLE *********\\n\")\n",
        "\n",
        "#print(model_CNN)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******** CUDA MODEL ENABLE *********\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rh1fBZcW98WZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definir otimizador e loss\n",
        "# Nota: testar outros otimizadores e funções de loss (em particular cross entropy)\n",
        "\n",
        "def optimizer_set(model,optimizer_method, learning_rate):\n",
        "  if optimizer_method == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "  elif optimizer_method == \"adadelta\":\n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"adagrad\":\n",
        "    optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"adamax\":\n",
        "    optimizer = torch.optim.Adamax(model.parameters(), lr = learning_rate)\n",
        "  elif optimizer_method == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)  \n",
        "  elif optimizer_method == \"rms\":\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "  return optimizer\n",
        "\n",
        "def loss_function_set(loss_function):\n",
        "  if loss_function == \"mse\":\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "  elif loss_function == \"nllos\":\n",
        "     loss_fn = torch.nn.NLLoss()\n",
        "  elif loss_function == \"cross\":\n",
        "     loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  return loss_fn\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZG-R1kCQEweC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(label, output_size):\n",
        "    \n",
        "    label_select = np.zeros(output_size)\n",
        "    label_select[label]=1\n",
        "    \n",
        "    return torch.Tensor(label_select)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p87aRLgR2pPo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, loss_function, dataset):\n",
        "  model.eval() # set model to Evaluate \"mode\"\n",
        " # losses = []\n",
        "  corrects = 0\n",
        "  current_total = 0\n",
        "  accuracies = 0\n",
        "  \n",
        " # loss_fn = loss_function_set(loss_function)\n",
        "  \n",
        "  for image, label in dataset:\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    outputs = model(image)\n",
        "    \n",
        "    _, predicted = outputs.max(1)\n",
        "    current_total += label.size(0)\n",
        "    corrects += predicted.eq(label).sum().item()\n",
        "    \n",
        "    current_total += 1\n",
        "  \n",
        "  accuracy = corrects/current_total\n",
        "\n",
        "  return accuracy #, np.mean(losses)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFVQOHzayfj6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training function"
      ]
    },
    {
      "metadata": {
        "id": "MELtsUbB98Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Realizar o treinamento aqui\n",
        "def fit(model, epochs, optimizer_method, loss_function, learning_rate):\n",
        "  \n",
        "  print(\"Opt Method:\", optimizer_method.upper(), \"| Loss Function:\", loss_function.upper(), \"| Learning Rate:\", learning_rate)\n",
        "  optimizer = optimizer_set(model,optimizer_method, learning_rate) #optimizer and Learning rate setter\n",
        "  loss_fn = loss_function_set(loss_function) \n",
        "  accuracies = []\n",
        "  losses = []\n",
        "  train_acc = []\n",
        "  for epoch in range(epochs):\n",
        "    model.train() # Set model to TRAIN \"mode\" (can be set to False for Test)\n",
        "    epoch_losses = []\n",
        "    for image,label in train_loader:\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()  # cleaning gradients between mini batches\n",
        "      outputs = model(image) \n",
        "      \n",
        "      if(loss_function == 'mse'):\n",
        "        label_target = one_hot(label,10) # one_hot to set the training class in the escalar\n",
        "        loss = loss_fn(outputs,label_target)\n",
        "      else: \n",
        "        loss = loss_fn(outputs, label)\n",
        "        \n",
        "      loss.backward() # Backpropagation \n",
        "      optimizer.step() # Optimization Method\n",
        "      \n",
        "      epoch_losses.append(loss.item())\n",
        "\n",
        "    losses.append(np.mean(epoch_losses)) # Append mean losses for each epoch\n",
        "   \n",
        "    \n",
        "    acc = evaluate(model, loss_function, train_loader)\n",
        "    train_acc.append(acc)\n",
        "    acc = evaluate(model, loss_function, test_loader) #evaluate\n",
        "    accuracies.append(acc)\n",
        "    \n",
        "    #if(epoch%10==0):\n",
        "    print(\"Epoch:\",epoch, \"- Average loss:\", np.mean(epoch_losses),\"- Accuracy:\", acc) # Print mean Loss for each epoch\n",
        " \n",
        "  return {\n",
        "      \"Model\": outputs,\n",
        "      \"Acc\": accuracies,\n",
        "      \"Train Acc\": train_acc,\n",
        "      \"Loss\": losses,\n",
        "      \"Name\": optimizer_method + \" | \" + loss_function + \" | \" + str(learning_rate),\n",
        "      \"Arc\": model\n",
        "      #\"Evaluate Train Loss\": train_losses,\n",
        "      \n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFeR8SBEw0ue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Your Model\n",
        "- Variable \"trained_models\" append all models trained\n",
        "- function \"fit\" train and return the Model and the all variable that will be used latter\n",
        "  - *fit(Model, Epochs, Optimizer method, Loss function, Learning rate)*"
      ]
    },
    {
      "metadata": {
        "id": "6kAvty-S98Wk",
        "colab_type": "code",
        "outputId": "536a1b37-dfca-471a-cc70-fae5c40fff6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "# TREINO ESTOCASTICO\n",
        "trained_models = []\n",
        "ep = 100 #epocas\n",
        "trained_models.append(fit(model_CNN,ep,\"adadelta\", \"cross\", 0.001))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Opt Method: ADADELTA | Loss Function: CROSS | Learning Rate: 0.0045\n",
            "Epoch: 0 - Average loss: 1.6830617524230624 - Accuracy: 0.34168\n",
            "Epoch: 1 - Average loss: 1.5377672936621951 - Accuracy: 0.3852\n",
            "Epoch: 2 - Average loss: 1.4426375259517175 - Accuracy: 0.41768\n",
            "Epoch: 3 - Average loss: 1.3623446414505758 - Accuracy: 0.44184\n",
            "Epoch: 4 - Average loss: 1.2920793051988135 - Accuracy: 0.45104\n",
            "Epoch: 5 - Average loss: 1.239948171953017 - Accuracy: 0.47208\n",
            "Epoch: 6 - Average loss: 1.189518184785422 - Accuracy: 0.48968\n",
            "Epoch: 7 - Average loss: 1.1482650941560761 - Accuracy: 0.50448\n",
            "Epoch: 8 - Average loss: 1.1052320990056008 - Accuracy: 0.50928\n",
            "Epoch: 9 - Average loss: 1.0699990495457836 - Accuracy: 0.51672\n",
            "Epoch: 10 - Average loss: 1.0370162801718148 - Accuracy: 0.51992\n",
            "Epoch: 11 - Average loss: 1.00845578246138 - Accuracy: 0.5332\n",
            "Epoch: 12 - Average loss: 0.9822507521431948 - Accuracy: 0.53536\n",
            "Epoch: 13 - Average loss: 0.9593352043926144 - Accuracy: 0.54768\n",
            "Epoch: 14 - Average loss: 0.9353346386477495 - Accuracy: 0.554\n",
            "Epoch: 15 - Average loss: 0.9143175487898133 - Accuracy: 0.55368\n",
            "Epoch: 16 - Average loss: 0.887558382002116 - Accuracy: 0.55968\n",
            "Epoch: 17 - Average loss: 0.8710153466108436 - Accuracy: 0.56632\n",
            "Epoch: 18 - Average loss: 0.8559620678234161 - Accuracy: 0.57328\n",
            "Epoch: 19 - Average loss: 0.8406543313351031 - Accuracy: 0.57664\n",
            "Epoch: 20 - Average loss: 0.8187744202555866 - Accuracy: 0.57752\n",
            "Epoch: 21 - Average loss: 0.8077399797799567 - Accuracy: 0.58544\n",
            "Epoch: 22 - Average loss: 0.785576736267301 - Accuracy: 0.58784\n",
            "Epoch: 23 - Average loss: 0.7720695653369011 - Accuracy: 0.5944\n",
            "Epoch: 24 - Average loss: 0.7566716607876947 - Accuracy: 0.59656\n",
            "Epoch: 25 - Average loss: 0.7481969352608984 - Accuracy: 0.59624\n",
            "Epoch: 26 - Average loss: 0.7293422196301145 - Accuracy: 0.60536\n",
            "Epoch: 27 - Average loss: 0.7179379558532725 - Accuracy: 0.60488\n",
            "Epoch: 28 - Average loss: 0.7115565682746475 - Accuracy: 0.61184\n",
            "Epoch: 29 - Average loss: 0.6949996417406196 - Accuracy: 0.61056\n",
            "Epoch: 30 - Average loss: 0.6840090520932594 - Accuracy: 0.61576\n",
            "Epoch: 31 - Average loss: 0.6684578914083278 - Accuracy: 0.61464\n",
            "Epoch: 32 - Average loss: 0.6643250445410447 - Accuracy: 0.62056\n",
            "Epoch: 33 - Average loss: 0.6509665768457694 - Accuracy: 0.62152\n",
            "Epoch: 34 - Average loss: 0.6362040082537358 - Accuracy: 0.62952\n",
            "Epoch: 35 - Average loss: 0.6341775053217101 - Accuracy: 0.62584\n",
            "Epoch: 36 - Average loss: 0.6252276625815524 - Accuracy: 0.6232\n",
            "Epoch: 37 - Average loss: 0.6093223645034236 - Accuracy: 0.6328\n",
            "Epoch: 38 - Average loss: 0.6058033096794128 - Accuracy: 0.63096\n",
            "Epoch: 39 - Average loss: 0.5997238025421984 - Accuracy: 0.6368\n",
            "Epoch: 40 - Average loss: 0.5865497367262307 - Accuracy: 0.6376\n",
            "Epoch: 41 - Average loss: 0.5788458614626224 - Accuracy: 0.63848\n",
            "Epoch: 42 - Average loss: 0.571303497349232 - Accuracy: 0.63576\n",
            "Epoch: 43 - Average loss: 0.5638990281429798 - Accuracy: 0.6404\n",
            "Epoch: 44 - Average loss: 0.560577453012201 - Accuracy: 0.6416\n",
            "Epoch: 45 - Average loss: 0.5547865918591399 - Accuracy: 0.6468\n",
            "Epoch: 46 - Average loss: 0.5375587324816221 - Accuracy: 0.64384\n",
            "Epoch: 47 - Average loss: 0.5309426591648784 - Accuracy: 0.6496\n",
            "Epoch: 48 - Average loss: 0.5266016364402674 - Accuracy: 0.65032\n",
            "Epoch: 49 - Average loss: 0.5217973445175705 - Accuracy: 0.64904\n",
            "Epoch: 50 - Average loss: 0.5108613832278733 - Accuracy: 0.64968\n",
            "Epoch: 51 - Average loss: 0.5060212227848959 - Accuracy: 0.6524\n",
            "Epoch: 52 - Average loss: 0.5010295834961948 - Accuracy: 0.65056\n",
            "Epoch: 53 - Average loss: 0.4941968401072884 - Accuracy: 0.6556\n",
            "Epoch: 54 - Average loss: 0.49026017212288087 - Accuracy: 0.65576\n",
            "Epoch: 55 - Average loss: 0.4837046875138734 - Accuracy: 0.65392\n",
            "Epoch: 56 - Average loss: 0.4772924785088135 - Accuracy: 0.65328\n",
            "Epoch: 57 - Average loss: 0.47282574643271896 - Accuracy: 0.65816\n",
            "Epoch: 58 - Average loss: 0.4650927242642401 - Accuracy: 0.66008\n",
            "Epoch: 59 - Average loss: 0.46128965872301175 - Accuracy: 0.66264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NEYr1-Z1wlq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text and Graphical Output"
      ]
    },
    {
      "metadata": {
        "id": "qD3jggrzfXa9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def graphical_outputs(trained_models):\n",
        "  plt.title(\"\\n\\nAccuracy \" + trained_models[0][\"Name\"].upper() +\"\\n\", fontsize=20, loc=\"left\")\n",
        "  plt.title(\"dotted line = train\")\n",
        "  for models in trained_models:\n",
        "    plt.plot(models[\"Acc\"], label = str(models[\"Arc\"]).partition(\"(\")[0])\n",
        "    plt.plot(models[\"Train Acc\"],\"--\") \n",
        "    print(models[\"Arc\"],\"\\n\", \"Mean ACC: \", np.mean(models[\"Acc\"]),\"\\nMax ACC:\", models[\"Acc\"][-1])\n",
        "\n",
        "  plt.legend(loc='best')\n",
        "  plt.show\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDxFC1RGjrLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "0336b718-485f-46b9-9ff0-67d6bdbf1faf"
      },
      "cell_type": "code",
      "source": [
        "graphical_outputs(trained_models)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layers): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (6): Dropout(p=0.1)\n",
            "    (7): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ") \n",
            " Mean ACC:  0.5876200000000001 \n",
            "Max ACC: 0.66264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAFQCAYAAAAfjWEEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}